{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNS: 28, DNSLE: 24, DNSF: 31, EXP: 13\n",
      "Total TRAINING cases: 96\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries and Datasets\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import binom,legendre, hermitenorm\n",
    "import warnings\n",
    "from timeit import default_timer as timer\n",
    "from joblib import Parallel, delayed\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "\n",
    "mpl.rcParams['font.family'] = 'Times New Roman'\n",
    "mpl.rcParams['mathtext.fontset'] = 'custom'\n",
    "mpl.rcParams['mathtext.rm'] = 'Times New Roman'\n",
    "mpl.rcParams['mathtext.it'] = 'Times New Roman:italic'\n",
    "mpl.rcParams['mathtext.bf'] = 'Times New Roman:bold'\n",
    "\n",
    "base_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'Results', 'csvFiles'))\n",
    "try:\n",
    "    data_path = base_path + '/rough_surface_statistics.csv'\n",
    "    rough_dat = pd.read_csv(data_path, header = None)\n",
    "    feature_name = rough_dat.iloc[0, :].values\n",
    "    data_rough = rough_dat.iloc[1:, 1:-1].values.astype(float)\n",
    "    labels = rough_dat.iloc[1:, -1].values\n",
    "    case_names = rough_dat.iloc[1:, 0].values\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found: {data_path}\")\n",
    "\n",
    "\n",
    "id_DNS,id_DNSle,id_DNSF,id_EXP,id_DNSlc = np.where((labels == 'DNS'))[0],np.where((labels == 'DNSLE'))[0],np.where((labels == 'DNSF'))[0],np.where((labels == 'EXP'))[0],np.where((labels == 'DNSLC'))[0]\n",
    "print(f\"DNS: {len(id_DNS)}, DNSLE: {len(id_DNSle)}, DNSF: {len(id_DNSF)}, EXP: {len(id_EXP)}\")\n",
    "print(f\"Total TRAINING cases: {data_rough.shape[0]-len(id_DNSlc)}\")\n",
    "\n",
    "\n",
    "used_col = [0, 1, 4, 5, 6, 8, 9, 11, 12, 13]\n",
    "input_data = data_rough[:, used_col]\n",
    "Sx,kavg,krms,Ra,Ix,Po,Ex,Sk,Ku,ks = input_data[:,0].reshape(-1, 1), input_data[:,1].reshape(-1, 1), \\\n",
    "    input_data[:,2].reshape(-1, 1), input_data[:,3].reshape(-1, 1), \\\n",
    "    input_data[:,4].reshape(-1, 1), input_data[:,5].reshape(-1, 1), \\\n",
    "    input_data[:,6].reshape(-1, 1), input_data[:,7].reshape(-1, 1), \\\n",
    "    input_data[:,8].reshape(-1, 1), input_data[:,9].reshape(-1, 1)\n",
    "kt,Iz,Ez = data_rough[:,3].reshape(-1, 1) , data_rough[:,7].reshape(-1, 1), data_rough[:,10].reshape(-1, 1)  # kt, Iz, Ez\n",
    "\n",
    "\n",
    "# Helper Funcs\n",
    "def cos(x):\n",
    "    return np.cos(x)\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def exp(x):\n",
    "    return np.exp(x)\n",
    "def square(x):\n",
    "    return np.square(x)\n",
    "def abs(x):\n",
    "    return np.abs(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your model to be analyzed\n",
    "class symbolic_model():\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def SrModel_cop50():\n",
    "        x1,y1,z1,u1,v1  = Po,Ex,Sk,kavg,Sx\n",
    "        # 50\"\n",
    "        out_tar = (square(cos(x1) - (x1 * exp(x1))) + 8.331)*\\\n",
    "            (tanh((y1 + -0.084) / 0.294))*\\\n",
    "            (tanh(z1) + (z1 / tanh(z1))) *\\\n",
    "            (u1 + ((u1 + -0.692) - (tanh(-0.024 / square(u1)) * exp(u1)))) *\\\n",
    "            (square(exp(v1)))\n",
    "\n",
    "        # print(f\"SR model's output for {len(id_used_)} ids\")\n",
    "        return out_tar\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def SrModel_4PCE(input_points):\n",
    "        x1,y1,z1,u1,v1  = input_points[:,0].reshape(-1, 1),input_points[:,1].reshape(-1, 1),input_points[:,2].reshape(-1, 1),input_points[:,3].reshape(-1, 1),input_points[:,4].reshape(-1, 1)\n",
    "        # 50\"   \n",
    "        out_tar = (square(cos(x1) - (x1 * exp(x1))) + 8.331)*\\\n",
    "            (tanh((y1 + -0.084) / 0.294))*\\\n",
    "            (tanh(z1) + (z1 / tanh(z1))) *\\\n",
    "            (u1 + ((u1 + -0.692) - (tanh(-0.024 / square(u1)) * exp(u1)))) *\\\n",
    "            (square(exp(v1)))\n",
    "        # print(f\"SR model's output for {input_points.shape[0]} samples. Rescaled input used.\\n\")\n",
    "        return out_tar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCE Smolyak grid. Not called when employing least squares PCE\n",
    "def columnize(*args):\n",
    "\n",
    "    column_arrays = []\n",
    "    for ele in args:\n",
    "        if isinstance(ele, (list, tuple)):\n",
    "            ele = np.array(ele)\n",
    "        ele.shape = (-1, 1)\n",
    "        column_arrays.append(ele)\n",
    "\n",
    "    return column_arrays\n",
    "\n",
    "def clencurt(rule=5, method='FFT'):\n",
    "\n",
    "    if method.upper() == 'FFT':\n",
    "        \n",
    "        if rule == 1:\n",
    "            x = np.array([0])\n",
    "            w = np.array([2])\n",
    "        else:\n",
    "            n = rule - 1\n",
    "            c = np.zeros((rule, 2))\n",
    "            c[:rule:2,0] = 2 / np.append([1], np.array([1-np.arange(2,rule,2)**2]))\n",
    "            c[1,1] = 1\n",
    "            f = np.fft.ifft(np.concatenate((c[:rule,:], c[-2:0:-1,:]),axis=0), axis=0).real\n",
    "            w = 2 * np.concatenate(([f[0,0]], 2*f[1:rule-1,0], [f[rule-1,0]]))/2\n",
    "            x = (rule-1) * f[:rule,1]\n",
    "            x = x[-1::-1]\n",
    "        return x, w\n",
    "    \n",
    "    elif method.upper() == 'EXPLICIT':\n",
    "        if rule == 1:\n",
    "            x = np.array([0])\n",
    "            w = np.array([2])\n",
    "        else:\n",
    "            n = rule - 1\n",
    "            # build points\n",
    "            theta = np.arange(rule) * np.pi / n\n",
    "            x = np.cos(theta)\n",
    "            w = 0\n",
    "\n",
    "            c = np.ones((rule))\n",
    "            c[1:-1] = 2\n",
    "            j = np.arange((n/2)//1) + 1\n",
    "            \n",
    "            b = 2 * np.ones(j.shape)\n",
    "            if np.mod(n/2,1) == 0:\n",
    "                b[int(n/2) - 1] = 1\n",
    "            \n",
    "            j.shape = (1, -1)\n",
    "            b.shape = (1, -1)\n",
    "            j_theta = j * theta.reshape(-1,1)\n",
    "            w = c/n * (1 - np.sum(b/(4*j**2 - 1) * np.cos(2*j_theta), axis=1))\n",
    "\n",
    "            x = np.round(x[-1::-1] * 1e13) / 1e13\n",
    "        return x, w\n",
    "\n",
    "def quad_coeff(rule=5, kind='GL'):\n",
    "\n",
    "    if kind.upper() == 'GL':\n",
    "        x, w = np.polynomial.legendre.leggauss(rule)\n",
    "        \n",
    "    elif kind.upper() == 'GH':\n",
    "        x, w = np.polynomial.hermite.hermgauss(rule)\n",
    "        \n",
    "    elif kind.upper() == 'CC':\n",
    "        x, w = clencurt(rule)\n",
    "\n",
    "    return x, w\n",
    "\n",
    "class PceSmolyakGrid():\n",
    "\n",
    "    def __init__(self, polynom, level):\n",
    "        \n",
    "        (self.x,\n",
    "         self.eps,\n",
    "         self.weight,\n",
    "         self.unique_x,\n",
    "         self.inverse_index) = self.smolyak_sparse_grid(polynom, level)\n",
    "\n",
    "\n",
    "    def smolyak_sparse_grid(self, polynom, level):\n",
    "\n",
    "        # min and max level\n",
    "        o_min = max([level + 1, polynom.dim])\n",
    "        o_max = level + polynom.dim\n",
    "        \n",
    "        # get multi-index for all level\n",
    "        comb = np.empty((0, polynom.dim), dtype=int)\n",
    "        for k in range(o_min, o_max+1):\n",
    "            multi_index, _ = self.index_with_sum(polynom.dim, k)\n",
    "            comb = np.append(comb, multi_index, axis=0)\n",
    "        \n",
    "        # initialize final array\n",
    "        x_points = np.empty((0, polynom.dim))\n",
    "        eps_points = np.empty((0, polynom.dim))\n",
    "        weights = np.empty((0,))\n",
    "\n",
    "        # define integration points and weights\n",
    "        for lev in comb:\n",
    "            local_x = []\n",
    "            local_eps = []\n",
    "            local_w = []\n",
    "            coeff = (-1)**(level + polynom.dim - np.sum(lev)) * binom(polynom.dim - 1, level + polynom.dim - np.sum(lev))\n",
    "            \n",
    "            # cycle on integration variables\n",
    "            for l, k, p in zip(lev, polynom.distrib, polynom.param):\n",
    "                # set integration type depending on distrib\n",
    "                if k.upper() == 'U':\n",
    "                    kind = 'CC'\n",
    "                elif k.upper() == 'N':\n",
    "                    kind = 'GH'\n",
    "                \n",
    "                # get number of integration points\n",
    "                n = self.growth_rule(l, kind=kind)\n",
    "                # get gauss points and weight\n",
    "                x0, w0 = quad_coeff(rule=n, kind=kind)\n",
    "\n",
    "                # change of variable\n",
    "                if (k.upper() == 'U'):\n",
    "                    eps = np.copy(x0)\n",
    "                    w = np.copy(w0) * 0.5\n",
    "                    if p != [-1, 1]:\n",
    "                        x = (p[1] - p[0]) / 2 * x0 + (p[1] + p[0]) / 2\n",
    "                    else:\n",
    "                        x = np.copy(x0)\n",
    "                    \n",
    "                elif (k.upper() == 'N'):\n",
    "                    eps = np.sqrt(2) * 1 * x0 + 0 \n",
    "                    x = eps * p[1] + p[0]\n",
    "                    w = w0 * (1 / np.sqrt(np.pi))\n",
    "\n",
    "                # store local points\n",
    "                local_x.append(x)\n",
    "                local_eps.append(eps)\n",
    "                local_w.append(w)\n",
    "            \n",
    "            # update final array\n",
    "            x_points = np.concatenate((x_points, np.concatenate(columnize(*np.meshgrid(*local_x)), axis=1)))\n",
    "            eps_points = np.concatenate((eps_points, np.concatenate(columnize(*np.meshgrid(*local_eps)), axis=1)))\n",
    "            weights = np.concatenate((weights, coeff * np.prod(np.concatenate(columnize(*np.meshgrid(*local_w)), axis=1),axis=1)))\n",
    "        \n",
    "        # get unique points\n",
    "        unique_x_points, inverse_index = np.unique(x_points, axis=0, return_inverse=True)\n",
    "\n",
    "        return x_points, eps_points, weights, unique_x_points, inverse_index\n",
    "\n",
    "\n",
    "    def index_with_sum(self, dim, val):\n",
    "\n",
    "        # check feasibility\n",
    "        if val < dim:\n",
    "            raise ValueError(f'dim={dim} --> minimum value for val=dim={dim} (here {val} is provided)')\n",
    "\n",
    "        k = np.ones(dim,dtype=int)\n",
    "        khat = k * (val - dim + 1)\n",
    "\n",
    "        index = np.empty((0, dim), dtype=int)\n",
    "\n",
    "        cnt = 0\n",
    "        p = 0\n",
    "\n",
    "        while k[dim - 1] < val:\n",
    "            if k[p] > khat[p]:\n",
    "                if (p + 1) != dim:\n",
    "                    k[p] = 1\n",
    "                    p += 1\n",
    "            else:\n",
    "                khat[:p] = khat[p] - k[p] + 1\n",
    "                k[0] = khat[0]\n",
    "                p = 0\n",
    "                cnt += 1\n",
    "                index = np.append(index, k.reshape(1,-1), axis=0)\n",
    "            \n",
    "            k[p] = k[p] + 1\n",
    "        return index, cnt\n",
    "\n",
    "\n",
    "    def growth_rule(self, level, kind='Legendre'):\n",
    "\n",
    "        method_map = {'GL':1, 'GH':1, 'CC':2}\n",
    "\n",
    "        if method_map[kind.upper()] == 1: \n",
    "            n = 2*level - 1\n",
    "        elif method_map[kind.upper()] == 2:\n",
    "            n = 1 if level == 1 else 2**(level - 1) + 1\n",
    "        \n",
    "        return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomial Chaos Expansion class\n",
    "class PolyChaos():\n",
    "\n",
    "    def __str__(self):\n",
    "        kmax = 5\n",
    "        msg = \"\"\n",
    "        \n",
    "        msg += \"Polynomial Chaos Expansion\\n\"\n",
    "        msg += \"--------------------------\\n\"\n",
    "        msg += f\"    dimensions: {self.dim}\\n\"\n",
    "        msg += f\"    order: {self.order}\\n\"\n",
    "        \n",
    "        msg += \"    distrib: [\"\n",
    "        for k, ele in enumerate(self.distrib):\n",
    "            if k > kmax - 1:\n",
    "                msg += ' ... '\n",
    "                break\n",
    "            elif k == len(self.distrib)  - 1:\n",
    "                msg += ele.upper()\n",
    "            else:\n",
    "                msg += ele.upper() + \" , \"\n",
    "        msg += \"]\\n\"\n",
    "\n",
    "        msg += \"    param: [\"\n",
    "        for k, ele in enumerate(self.param):\n",
    "            if k > kmax - 1:\n",
    "                msg += ' ... '\n",
    "                break\n",
    "            elif k == len(self.param)  - 1:\n",
    "                msg += str(ele)\n",
    "            else:\n",
    "                msg += str(ele) + \" , \"\n",
    "        msg += \"]\\n\"\n",
    "\n",
    "        msg += \"    coeff: [\"\n",
    "        if self.coeff.size == 0:\n",
    "            msg += \" to be computed \"\n",
    "        else:\n",
    "            for k, ele in enumerate(self.coeff):\n",
    "                if k > kmax - 1:\n",
    "                    msg += ' ... '\n",
    "                    break\n",
    "                elif k == len(self.param) - 1:\n",
    "                    msg += str(ele)\n",
    "                else:\n",
    "                    msg += str(ele) + \" , \"\n",
    "        msg += \"]\\n\"\n",
    "        \n",
    "        return msg\n",
    "\n",
    "    def __init__(self, order, distrib, param):\n",
    "\n",
    "        if len(distrib) != len(param):\n",
    "            raise ValueError('distrib and param not the same length')\n",
    "        \n",
    "        self.dim = len(distrib)\n",
    "        self.order = order\n",
    "        self.distrib = distrib\n",
    "        self.param = param\n",
    "        self.coeff = np.empty(0)\n",
    "        self.grid = None\n",
    "        self.mu = None\n",
    "        self.sigma = None\n",
    "\n",
    "        (self.nt,\n",
    "         self.multi_index,\n",
    "         self.basis) = self.create_instance(order, distrib)\n",
    "    \n",
    "\n",
    "    def create_instance(self, order, distrib):\n",
    "\n",
    "        # generate multi index\n",
    "        multi_index, nt = self.generate_multi_index(order)\n",
    "\n",
    "        # create multivariate polynomials basis \n",
    "        def basis(index, eps):\n",
    "\n",
    "            if index > (nt - 1):\n",
    "                raise ValueError(f'max index possible is nt-1={self.nt-1}')\n",
    "            if isinstance(eps, (list, tuple)):\n",
    "                eps = np.array(eps)\n",
    "\n",
    "            i = self.multi_index[index]\n",
    "            \n",
    "            y = np.ones(eps.shape[0])\n",
    "           \n",
    "            for k, dist in enumerate(distrib):\n",
    "                if dist.upper() == 'U':\n",
    "                    y = y * np.polyval(legendre(i[k]), eps[..., k])\n",
    "                elif dist.upper() == 'N':\n",
    "                    y = y * np.polyval(hermitenorm(i[k]), eps[..., k])\n",
    "            \n",
    "            return y\n",
    "        \n",
    "        return nt, multi_index, basis\n",
    "\n",
    "        \n",
    "    def generate_multi_index(self, order):\n",
    "    \n",
    "        index = np.empty((0, self.dim), dtype=int)\n",
    "        cnt = 0\n",
    "\n",
    "        for val in range(order + 1):\n",
    "            k = np.zeros(self.dim,dtype=int)\n",
    "            khat = np.ones_like(k) * val    \n",
    "            p = 0\n",
    "\n",
    "            while k[self.dim - 1] <= val:\n",
    "                if k[p] > khat[p]:\n",
    "                    if (p + 1) != self.dim:\n",
    "                        k[p] = 0\n",
    "                        p += 1\n",
    "                else:\n",
    "                    khat[:p] = khat[p] - k[p]\n",
    "                    k[0] = khat[0]\n",
    "                    p = 0\n",
    "                    cnt += 1\n",
    "                    index = np.append(index, k.reshape(1,-1), axis=0)\n",
    "                \n",
    "                k[p] = k[p] + 1\n",
    "        \n",
    "        return index, cnt\n",
    "\n",
    "\n",
    "    def norm_factor(self, multi_index):\n",
    "\n",
    "        factor = 1\n",
    "        for k, index in enumerate(multi_index):\n",
    "            if self.distrib[k].upper() == 'U':\n",
    "                factor = factor * (2 * index + 1) / 1\n",
    "            elif self.distrib[k].upper() == 'N':\n",
    "                factor = factor / math.factorial(index)\n",
    "        \n",
    "        return factor\n",
    "\n",
    "    \n",
    "    def spectral_projection(self, fun, level,):\n",
    "        \n",
    "        # create sparse grid. Not called when employing least squares PCE\n",
    "        # ------------------\n",
    "        t1 = timer()\n",
    "        print(\"* generation of smolyak sparse grid ... \", end=' ', flush=True)\n",
    "        #\n",
    "        self.grid = PceSmolyakGrid(self, level)\n",
    "\n",
    "        # evaluate function at unique points\n",
    "        # ----------------------------------\n",
    "        \n",
    "        unique_y = fun(self.grid.unique_x)\n",
    "        #\n",
    "                \n",
    "        # evaluate function at all points\n",
    "        # -------------------------------\n",
    "        print(f\"* build complete function output ({self.grid.x.shape[0]} points) ... \", end=' ', flush=True)\n",
    "            #\n",
    "        y = unique_y[self.grid.inverse_index, ...]\n",
    "        \n",
    "        # coefficient computation\n",
    "        # -----------------------\n",
    "        print(\"* coefficient computation ... \", end=' ', flush=True)\n",
    "        \n",
    "        # function to compute the k-th coefficient\n",
    "        def compute_k_coeff(k):\n",
    "            factor = self.norm_factor(self.multi_index[k])\n",
    "            return factor * np.sum(y.flatten() * self.basis(k, self.grid.eps).flatten() * self.grid.weight.flatten())\n",
    "        # parallel computation of all coefficients\n",
    "        coeff = Parallel(n_jobs=-1, verbose=0)(map(delayed(compute_k_coeff), range(self.nt)))\n",
    "        self.coeff = np.array(coeff)\n",
    "    \n",
    "\n",
    "    def create_latin_hypercube_samples(self,sp_num,rd_state=None):\n",
    "\n",
    "        dim = self.dim\n",
    "        sample_points = np.zeros((sp_num, dim))\n",
    "        rng = np.random.RandomState(rd_state) if rd_state is not None else np.random\n",
    "\n",
    "        # create the latin hyper-cube \n",
    "        randoms = rng.random(sp_num * dim).reshape((dim, sp_num))\n",
    "        for dim_ in range(dim):\n",
    "            perm = rng.permutation(sp_num)  # pylint: disable=no-member\n",
    "            randoms[dim_] = (perm + randoms[dim_]) / sp_num\n",
    "\n",
    "        for k, (dist,param) in enumerate(zip(self.distrib,self.param)):\n",
    "        # rescale          \n",
    "        # from [0, 1] to [a,b] for uniform distribution\n",
    "        # from [0, 1] to [nu,sigma] for normal distribution \n",
    "            if dist.upper() == 'N':\n",
    "                nu,sigma = param\n",
    "                std_nm = stats.norm.ppf(randoms.T[:,k])\n",
    "                sample_points[:,k] = nu + sigma*std_nm\n",
    "            elif dist.upper() == 'U':\n",
    "                min_v,max_v = param\n",
    "                sample_points[:,k] = min_v + (max_v-min_v)*randoms.T[:,k]\n",
    "        \n",
    "        print(f'Latin Hypercube sampling: {sp_num} samples in {dim} dimensions created.\\n')\n",
    "        return sample_points\n",
    "    \n",
    "\n",
    "    def regression_fit(self,  points, y_samples):\n",
    "        Ns = points.shape[0]\n",
    "        if Ns < self.nt:\n",
    "            raise ValueError(f'number of points ({Ns}) must be >= number of basis functions ({self.nt})\\nIncrease Ns or decrease PCE order.')\n",
    "        if y_samples.shape[0] != Ns:\n",
    "            raise ValueError(f'number of points {points.shape} and samples {y_samples.shape} must be the same')\n",
    "\n",
    "        # change of limited range\n",
    "        std_points = np.zeros_like(points)\n",
    "        for k, (dist,param) in enumerate(zip(self.distrib,self.param)):\n",
    "            if dist.upper() == 'U':\n",
    "                a, b = param\n",
    "                std_points[:,k] = (2 * points[:,k]-a-b)/(b-a)\n",
    "            elif dist.upper()=='N':\n",
    "                nu,sigma = param\n",
    "                std_points[:,k] = (points[:,k]-nu)/sigma\n",
    "\n",
    "        # build the regression matrix\n",
    "        A = np.zeros((Ns,self.nt))\n",
    "        for k in range(self.nt):\n",
    "            A[:,k] = self.basis(k,std_points)\n",
    "\n",
    "        # compute the coefficients\n",
    "        coeff, residuals, rank, singular_vals = np.linalg.lstsq(A, y_samples, rcond = None)\n",
    "\n",
    "        self.coeff = coeff.flatten()\n",
    "\n",
    "        if rank<min(A.shape):\n",
    "            warnings.warn(f'Regression matrix is rank deficient.Rank={rank}, expected min={min(A.shape)}')\n",
    "\n",
    "        print(f'Regression-Fit: PCE order={self.nt},residuals(L2)={np.sqrt(residuals/Ns)}\\n')\n",
    "\n",
    "    def compare_on_myData(self,input_latin,verbose = 'y',thres = 0.4):\n",
    "        sr_rough = symbolic_model()\n",
    "        real_samples = np.concatenate((Po,Ex,Sk,kavg,Sx), axis=1)\n",
    "        sr_output_real = sr_rough.SrModel_cop50().squeeze()\n",
    "        y_samples = sr_rough.SrModel_4PCE(input_latin).squeeze()\n",
    "        output_pce = self.evaluate(input_latin)\n",
    "        pce_output_real = self.evaluate(real_samples)\n",
    "\n",
    "        if verbose =='y':\n",
    "            figs,axes = plt.subplots(1,2,figsize = (6,3))\n",
    "            axes[0].plot(y_samples, output_pce, 'o',color = '#c20078',markerfacecolor='none')\n",
    "            axes[0].set_title('PCE on Latin-samples')\n",
    "            id_less = np.where(np.abs((sr_output_real-pce_output_real)/sr_output_real)<thres)\n",
    "            axes[1].plot(sr_output_real[id_less], pce_output_real[id_less], 'o',color = '#00c251',markerfacecolor = 'none')\n",
    "            axes[1].set_title(f'PCE on Real-samples')\n",
    "            axes[1].text(0.1,0.9,f'{np.array(id_less).shape[1]}/96 in {thres*100}%', fontsize=12, transform=axes[1].transAxes,\n",
    "                        bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "            print(f\"Rough dataset {np.array(id_less).shape[1]}/96 in {thres*100}%\\n\")\n",
    "            plt.show()\n",
    "        \n",
    "        return [output_pce, y_samples, pce_output_real, sr_output_real]\n",
    "\n",
    "\n",
    "    def norm_fit(self, plot='n'):\n",
    "        \n",
    "        # evaluation of the mean\n",
    "        self.mu = self.coeff[0]\n",
    "        \n",
    "        # evaluation of the standard deviation\n",
    "        c_quad = self.coeff[1:] ** 2\n",
    "        psi_quad = np.array([1/self.norm_factor(k) for k in self.multi_index[1:]])\n",
    "        self.sigma = np.sqrt(np.sum(c_quad * psi_quad))\n",
    "\n",
    "        if plot.lower() == 'y':\n",
    "            # check if mpl is interactive\n",
    "            if not mpl.is_interactive():\n",
    "                plt.ion()\n",
    "\n",
    "            # create data\n",
    "            x = np.linspace(-4*self.sigma, 4*self.sigma, 501) + self.mu\n",
    "            y = 1 / np.sqrt(2 * np.pi * self.sigma**2) * np.exp(-(x - self.mu)**2 / (2 * self.sigma**2))\n",
    "\n",
    "            # plot\n",
    "            hp = plt.figure()\n",
    "            plt.plot(x, y , linewidth=2)\n",
    "            plt.xlabel('x', fontsize=14)\n",
    "            plt.ylabel('y', fontsize=14)\n",
    "            plt.xticks(fontsize=14)\n",
    "            plt.yticks(fontsize=14)\n",
    "            \n",
    "            # text box\n",
    "            ax = plt.gca()\n",
    "            props = dict(boxstyle='round', facecolor='white', alpha=0.9, linewidth=2)\n",
    "            ax.text(0.05, 0.95, r\"$\\mu={self.mu :.4f}$\\n$\\sigma={self.sigma  :.4f}$\",\n",
    "                    verticalalignment='top', bbox=props, fontsize=14, transform=ax.transAxes)\n",
    "            \n",
    "            # set grid and layout\n",
    "            plt.grid()\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # return handle to plot\n",
    "            return hp\n",
    "    \n",
    "\n",
    "    def sobol(self, index):\n",
    "        \"\"\"\n",
    "        SOBOL computes the Sobol' indices for a given PCE expansion.\n",
    "\n",
    "        Paramaters\n",
    "        ----------\n",
    "        index (list) :\n",
    "            list with index, e.g. [1,2] for having S12, [[1], [1,2,3]] for\n",
    "            having S1 and S123\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # check precedences\n",
    "        if self.sigma is None:\n",
    "            raise ValueError(\"norm_fit() must be called before sobol() can be executed\")\n",
    "\n",
    "        # handle input type\n",
    "        if not isinstance(index[0], (list, tuple)):\n",
    "            index = [index]\n",
    "        \n",
    "        sobol = []\n",
    "        for idx in index:\n",
    "            # create complementary index\n",
    "            zero_based_index = [k - 1 for k in idx]\n",
    "            all_index = np.array(range(len(self.distrib)))\n",
    "            other_index = np.setdiff1d(all_index, zero_based_index)\n",
    "\n",
    "            # find elements\n",
    "            coeff_index = np.array([True] * (self.multi_index.shape[0] - 1))\n",
    "            for ele in zero_based_index:\n",
    "                coeff_index = coeff_index * (self.multi_index[1:, ele] != 0)\n",
    "            for ele in other_index:\n",
    "                coeff_index = coeff_index * (self.multi_index[1:, ele] == 0)\n",
    "            \n",
    "            # computation of the index\n",
    "            c_quad = self.coeff[1:] ** 2\n",
    "            psi_quad = np.array([1/self.norm_factor(k) for k in self.multi_index[1:]])\n",
    "            sobol.append(np.sum(c_quad[coeff_index] * psi_quad[coeff_index]) / (self.sigma ** 2))\n",
    "        \n",
    "        # prepare output type\n",
    "        if len(sobol) == 1:\n",
    "            sobol = sobol[0]\n",
    "        \n",
    "        return sobol\n",
    "\n",
    "\n",
    "    def evaluate(self, points):\n",
    "        \n",
    "        if self.coeff.shape == (0, ):\n",
    "            import warnings\n",
    "            warnings.warn('PCE coeffiecients are not yet computed.')\n",
    "        else:            \n",
    "            # initialization\n",
    "            std_points = np.zeros_like(points)\n",
    "\n",
    "            # change of coordinates\n",
    "            for k, (dist, param) in enumerate(zip(self.distrib, self.param)):\n",
    "                if dist.upper() == 'U':\n",
    "                    std_points[:, k] = (param[0] + param[1] - 2 * points[:, k]) / (param[0] - param[1])\n",
    "                elif dist.upper() == 'N':\n",
    "                    std_points[:, k] = (points[:,k] -  param[0]) / param[1]\n",
    "            \n",
    "            for k in range(self.nt):\n",
    "                if k == 0:\n",
    "                    y = self.coeff[k] * self.basis(k, std_points)\n",
    "                else:\n",
    "                    y += self.coeff[k] * self.basis(k, std_points)\n",
    "            \n",
    "            return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an example of usage\n",
    "def main(my_pceParams):\n",
    "\n",
    "    pce_4SR = PolyChaos(order=my_pceParams['pce_order'], distrib=my_pceParams['distribution'], param=my_pceParams['parameters'])\n",
    "    sr_rough = symbolic_model()\n",
    "    input_samples_ = pce_4SR.create_latin_hypercube_samples(sp_num=my_pceParams['Laint_sample_num'], rd_state=my_pceParams['random_state'])\n",
    "    y_samples = sr_rough.SrModel_4PCE(input_samples_)\n",
    "    pce_4SR.regression_fit(input_samples_, y_samples)\n",
    "    pce_4SR.norm_fit(plot='n')\n",
    "    calc_ = pce_4SR.compare_on_myData(input_samples_,verbose = 'y',thres = 0.35)\n",
    "\n",
    "    # Po Ex Sk kavg Sx --- 1 2 3 4 5\n",
    "    sobol_idx = pce_4SR.sobol([[1],[2],[3],[4],[5],[2,3]])\n",
    "    print(f'Sobol indices for 5 features: \\nPo Ex Sk kavg Sx Ex*Sk\\n{np.array(sobol_idx)}\\nToal is {np.sum(sobol_idx)}\\n')\n",
    "    return sobol_idx,calc_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
